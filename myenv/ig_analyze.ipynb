{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sqlite3\n",
    "import instaloader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import color, feature\n",
    "from collections import Counter\n",
    "from scipy.stats import skew, kurtosis\n",
    "import cv2\n",
    "from datetime import timedelta, datetime, timezone\n",
    "\n",
    "# Check required libraries\n",
    "def check_libraries():\n",
    "    required_libraries = {\n",
    "        'numpy': 'numpy',\n",
    "        'Pillow': 'PIL',\n",
    "        'scikit-learn': 'sklearn',\n",
    "        'scikit-image': 'skimage',\n",
    "        'opencv-python': 'cv2',\n",
    "        'scipy': 'scipy'\n",
    "    }\n",
    "\n",
    "    missing_libraries = []\n",
    "\n",
    "    for pip_name, import_name in required_libraries.items():\n",
    "        try:\n",
    "            __import__(import_name)\n",
    "        except ImportError:\n",
    "            missing_libraries.append(pip_name)\n",
    "\n",
    "    if missing_libraries:\n",
    "        print(f\"The following libraries are required but not installed: {', '.join(missing_libraries)}\")\n",
    "        print(\"Please install them using pip:\")\n",
    "        print(f\"pip install {' '.join(missing_libraries)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# Perform the library check\n",
    "check_libraries()\n",
    "\n",
    "# Define the database path\n",
    "DATABASE_PATH = os.path.join(\"/Users/greyson/Projects/custom_gallery/gallery/prisma\", 'image_analysis.db')\n",
    "\n",
    "def connect_db():\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    conn.execute('PRAGMA foreign_keys = ON;')  # Enable foreign key support\n",
    "    return conn\n",
    "\n",
    "# Initialize the database and create tables if they don't exist\n",
    "def initialize_database():\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Enable foreign key support\n",
    "    cursor.execute('PRAGMA foreign_keys = ON;')\n",
    "\n",
    "    # Create Posts table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Posts (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        shortcode TEXT UNIQUE,\n",
    "        username TEXT,\n",
    "        caption TEXT,\n",
    "        post_date TEXT\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    # Create Images table with foreign keys to Posts\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Images (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        absolute_file_path TEXT UNIQUE,\n",
    "        relative_file_path TEXT UNIQUE,\n",
    "        filename TEXT,\n",
    "        processed_at TEXT,\n",
    "        post_id INTEGER,\n",
    "        width INTEGER,\n",
    "        height INTEGER,\n",
    "        FOREIGN KEY(post_id) REFERENCES Posts(id) ON DELETE CASCADE\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    # Create Luminance table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Luminance (\n",
    "        image_id INTEGER PRIMARY KEY,\n",
    "        mean_luminance REAL,\n",
    "        median_luminance REAL,\n",
    "        std_luminance REAL,\n",
    "        dynamic_range REAL,\n",
    "        rms_contrast REAL,\n",
    "        michelson_contrast REAL,\n",
    "        luminance_skewness REAL,\n",
    "        luminance_kurtosis REAL,\n",
    "        min_luminance REAL,\n",
    "        max_luminance REAL,\n",
    "        FOREIGN KEY(image_id) REFERENCES Images(id) ON DELETE CASCADE\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    # Create Saturation table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Saturation (\n",
    "        image_id INTEGER PRIMARY KEY,\n",
    "        mean_saturation REAL,\n",
    "        median_saturation REAL,\n",
    "        std_saturation REAL,\n",
    "        FOREIGN KEY(image_id) REFERENCES Images(id) ON DELETE CASCADE\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    # Create GLCM table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS GLCM (\n",
    "        image_id INTEGER PRIMARY KEY,\n",
    "        contrast REAL,\n",
    "        correlation REAL,\n",
    "        FOREIGN KEY(image_id) REFERENCES Images(id) ON DELETE CASCADE\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    # Create Laplacian table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Laplacian (\n",
    "        image_id INTEGER PRIMARY KEY,\n",
    "        variance REAL,\n",
    "        FOREIGN KEY(image_id) REFERENCES Images(id) ON DELETE CASCADE\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    # Create KMeansClustering table with 'id' as PRIMARY KEY\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS KMeansClustering (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        image_id INTEGER,\n",
    "        num_clusters INTEGER,\n",
    "        FOREIGN KEY(image_id) REFERENCES Images(id) ON DELETE CASCADE\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    # Modify Clusters table to include LAB values\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Clusters (\n",
    "        clustering_id INTEGER,\n",
    "        cluster_index INTEGER,\n",
    "        r INTEGER,\n",
    "        g INTEGER,\n",
    "        b INTEGER,\n",
    "        l REAL,\n",
    "        a REAL,\n",
    "        b_channel REAL,\n",
    "        count INTEGER,\n",
    "        percentage REAL,\n",
    "        FOREIGN KEY(clustering_id) REFERENCES KMeansClustering(id) ON DELETE CASCADE,\n",
    "        PRIMARY KEY (clustering_id, cluster_index)\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Database initialized successfully.\")\n",
    "\n",
    "# Initialize the database (only run once)\n",
    "if not os.path.exists(DATABASE_PATH):\n",
    "        initialize_database()\n",
    "else:\n",
    "    print(\"Database already exists.\")\n",
    "\n",
    "# Create an Instaloader instance with custom directory and filename patterns\n",
    "L = instaloader.Instaloader(\n",
    "    dirname_pattern='../gallery/public/img/{target}/{date_utc:%Y-%m-%d_%H-%M-%S}_{shortcode}',\n",
    "    filename_pattern='{filename}',\n",
    "    download_videos=False,             # Skip downloading videos\n",
    "    download_video_thumbnails=False    # Skip downloading video thumbnails\n",
    ")\n",
    "\n",
    "# Provide your Instagram login credentials securely\n",
    "# import getpass\n",
    "\n",
    "# insta_username = input(\"Enter your Instagram username: \")\n",
    "# insta_password = getpass.getpass(\"Enter your Instagram password: \")\n",
    "\n",
    "# Perform login\n",
    "# try:\n",
    "#     L.login(insta_username, insta_password)\n",
    "# except instaloader.exceptions.BadCredentialsException:\n",
    "#     print(\"Invalid credentials. Please check your username and password.\")\n",
    "#     sys.exit(1)\n",
    "# except instaloader.exceptions.TwoFactorAuthRequiredException:\n",
    "#     code = input(\"Enter the 2FA code sent to your device: \")\n",
    "#     L.two_factor_login(code)\n",
    "\n",
    "# Replace 'instagram_username' with the actual Instagram username\n",
    "username = 'tomopoole'  # e.g., 'greyson.color'\n",
    "\n",
    "# Get the profile metadata\n",
    "profile = instaloader.Profile.from_username(L.context, username)\n",
    "\n",
    "# Fetch all posts from the profile\n",
    "posts = list(profile.get_posts())  # Convert to list to calculate length\n",
    "\n",
    "total_posts = len(posts)  # Get total number of posts\n",
    "print(f\"Total posts to download: {total_posts}\")\n",
    "\n",
    "# Track progress and download time\n",
    "start_time = time.time()  # Track the time when the download starts\n",
    "\n",
    "# Connect to the database\n",
    "conn = connect_db()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def is_similar(row, tolerance=10):\n",
    "    \"\"\"\n",
    "    Check if all pixels in the row are similar within the given tolerance.\n",
    "    \"\"\"\n",
    "    # Compute the difference between max and min for each channel\n",
    "    diff = row.max(axis=0) - row.min(axis=0)\n",
    "    return np.all(diff < tolerance)\n",
    "\n",
    "def remove_letterbox(image_np, std_threshold=5, min_letterbox_height=10):\n",
    "    \"\"\"\n",
    "    Detect and remove letterboxing from the top and bottom of the image\n",
    "    using standard deviation of pixel intensities along rows.\n",
    "    Returns the top and bottom letterbox heights, and the cropped image.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    grayscale = np.mean(image_np, axis=2)\n",
    "\n",
    "    # Compute the standard deviation along each row\n",
    "    std_dev = np.std(grayscale, axis=1)\n",
    "\n",
    "    # Normalize the standard deviation\n",
    "    std_dev_normalized = (std_dev - np.min(std_dev)) / (np.max(std_dev) - np.min(std_dev)) * 100\n",
    "\n",
    "    # Find indices where std_dev exceeds the threshold\n",
    "    content_indices = np.where(std_dev_normalized > std_threshold)[0]\n",
    "\n",
    "    if content_indices.size == 0:\n",
    "        print(\"No content detected in the image.\")\n",
    "        return 0, 0, image_np\n",
    "\n",
    "    # Determine the top and bottom rows of the content area\n",
    "    top_row = content_indices[0]\n",
    "    bottom_row = content_indices[-1]\n",
    "\n",
    "    # Calculate letterbox heights\n",
    "    top_height = top_row\n",
    "    bottom_height = image_np.shape[0] - bottom_row - 1\n",
    "\n",
    "    # Ensure that the detected letterbox heights are at least min_letterbox_height\n",
    "    if top_height < min_letterbox_height:\n",
    "        top_height = 0\n",
    "    if bottom_height < min_letterbox_height:\n",
    "        bottom_height = 0\n",
    "\n",
    "    # Crop the image to remove letterboxes\n",
    "    cropped_image = image_np[top_height:image_np.shape[0] - bottom_height, :, :]\n",
    "    print(f\"Removed letterbox: Top={top_height}px, Bottom={bottom_height}px\")\n",
    "    return top_height, bottom_height, cropped_image\n",
    "\n",
    "def insert_luminance(conn, image_id, luminance_metrics):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Luminance (\n",
    "        image_id, mean_luminance, median_luminance, std_luminance,\n",
    "        dynamic_range, rms_contrast, michelson_contrast,\n",
    "        luminance_skewness, luminance_kurtosis,\n",
    "        min_luminance, max_luminance\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        luminance_metrics[\"Mean Luminance\"],\n",
    "        luminance_metrics[\"Median Luminance\"],\n",
    "        luminance_metrics[\"Std Luminance\"],\n",
    "        luminance_metrics[\"Dynamic Range\"],\n",
    "        luminance_metrics[\"RMS Contrast\"],\n",
    "        luminance_metrics[\"Michelson Contrast\"],\n",
    "        luminance_metrics[\"Luminance Skewness\"],\n",
    "        luminance_metrics[\"Luminance Kurtosis\"],\n",
    "        luminance_metrics[\"Min Luminance\"],\n",
    "        luminance_metrics[\"Max Luminance\"]\n",
    "    ))\n",
    "    conn.commit()\n",
    "\n",
    "def insert_saturation(conn, image_id, saturation_metrics):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Saturation (\n",
    "        image_id, mean_saturation, median_saturation, std_saturation\n",
    "    ) VALUES (?, ?, ?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        saturation_metrics[\"Mean Saturation\"],\n",
    "        saturation_metrics[\"Median Saturation\"],\n",
    "        saturation_metrics[\"Std Saturation\"]\n",
    "    ))\n",
    "    conn.commit()\n",
    "\n",
    "def insert_glcm(conn, image_id, glcm_metrics):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    INSERT INTO GLCM (\n",
    "        image_id, contrast, correlation\n",
    "    ) VALUES (?, ?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        glcm_metrics[\"GLCM Contrast\"],\n",
    "        glcm_metrics[\"GLCM Correlation\"]\n",
    "    ))\n",
    "    conn.commit()\n",
    "\n",
    "def insert_laplacian(conn, image_id, laplacian_var):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Laplacian (\n",
    "        image_id, variance\n",
    "    ) VALUES (?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        laplacian_var\n",
    "    ))\n",
    "    conn.commit()\n",
    "\n",
    "def insert_kmeans_clustering(conn, image_id, clustering_data):\n",
    "    cursor = conn.cursor()\n",
    "    num_clusters = clustering_data[\"Number of Clusters\"]\n",
    "    cursor.execute('''\n",
    "    INSERT INTO KMeansClustering (\n",
    "        image_id, num_clusters\n",
    "    ) VALUES (?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        num_clusters\n",
    "    ))\n",
    "    conn.commit()\n",
    "    # Retrieve the last inserted row id for KMeansClustering\n",
    "    clustering_id = cursor.lastrowid\n",
    "\n",
    "    clusters_rgb = clustering_data[\"Cluster Centers (RGB)\"]\n",
    "    clusters_lab = clustering_data[\"Cluster Centers (LAB)\"]\n",
    "    counts = clustering_data[\"Cluster Counts\"]\n",
    "    percentages = clustering_data[\"Cluster Percentages\"]\n",
    "\n",
    "    for idx, (color_rgb, color_lab, count, pct) in enumerate(zip(clusters_rgb, clusters_lab, counts, percentages)):\n",
    "        r, g, b = color_rgb\n",
    "        l_val, a_val, b_val = color_lab\n",
    "        cursor.execute('''\n",
    "        INSERT INTO Clusters (\n",
    "            clustering_id, cluster_index, r, g, b, l, a, b_channel, count, percentage\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            clustering_id,\n",
    "            idx + 1,  # cluster_index starting from 1\n",
    "            r,\n",
    "            g,\n",
    "            b,\n",
    "            l_val,\n",
    "            a_val,\n",
    "            b_val,\n",
    "            count,\n",
    "            float(pct)  # Directly use pct as it's already a float\n",
    "        ))\n",
    "    conn.commit()\n",
    "\n",
    "def process_image(image_path, image_id, conn):\n",
    "    \"\"\"\n",
    "    Process a single image: remove letterbox, perform k-means clustering,\n",
    "    compute metrics, and save them to the SQLite database.\n",
    "    Returns True if processed successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found at path: {image_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {image_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    # Check if the image is entirely one color\n",
    "    if len(np.unique(image_np.reshape(-1, image_np.shape[2]), axis=0)) == 1:\n",
    "        # Image is entirely one color\n",
    "        os.remove(image_path)\n",
    "        print(f\"Image {image_path} is entirely one color. Deleted.\")\n",
    "        # Delete the record from the Images table\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('DELETE FROM Images WHERE id = ?', (image_id,))\n",
    "        conn.commit()\n",
    "        return False  # Skip further processing\n",
    "\n",
    "    # Ensure the image is in RGB format\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "\n",
    "    # Remove alpha channel if present\n",
    "    if image_np.shape[2] == 4:\n",
    "        image_np = image_np[:, :, :3]\n",
    "\n",
    "    # *** Detect and Remove Letterbox using the new method ***\n",
    "    std_threshold = 7            # Standard deviation threshold\n",
    "    min_letterbox_height = 40    # Minimum height in pixels to consider as letterbox\n",
    "\n",
    "    # top_height, bottom_height, image_np = remove_letterbox(image_np, std_threshold, min_letterbox_height)\n",
    "\n",
    "    # *** Save the cropped image back to the original path ***\n",
    "    # Convert numpy array back to PIL Image\n",
    "    cropped_image = Image.fromarray(image_np)\n",
    "    # Save the cropped image, overwriting the original image\n",
    "    cropped_image.save(image_path)\n",
    "\n",
    "    # Get the width and height of the cropped image\n",
    "    height, width, channels = image_np.shape\n",
    "\n",
    "    # Update the Images table with letterbox heights and width/height\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    UPDATE Images\n",
    "    SET width = ?, height = ?\n",
    "    WHERE id = ?\n",
    "    ''', (width, height, image_id))\n",
    "    conn.commit()\n",
    "\n",
    "    # Check if the image is entirely one color after cropping\n",
    "    if len(np.unique(image_np.reshape(-1, image_np.shape[2]), axis=0)) == 1:\n",
    "        # Image is entirely one color after cropping\n",
    "        os.remove(image_path)\n",
    "        print(f\"Image {image_path} is entirely one color after cropping. Deleted.\")\n",
    "        # Delete the record from the Images table\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('DELETE FROM Images WHERE id = ?', (image_id,))\n",
    "        conn.commit()\n",
    "        return False  # Skip further processing\n",
    "\n",
    "    # Proceed with image processing\n",
    "    # Step 2: Normalize and convert to LAB color space\n",
    "    image_normalized = image_np / 255.0\n",
    "    image_lab = color.rgb2lab(image_normalized)\n",
    "\n",
    "    # Step 3: Reshape image data for clustering\n",
    "    pixels_lab = image_lab.reshape(-1, 3)\n",
    "\n",
    "    # Step 4: Perform k-means clustering with k=8\n",
    "    k = 8  # Set the number of clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(pixels_lab)\n",
    "\n",
    "    # Step 5: Process cluster centers\n",
    "    cluster_centers_lab = kmeans.cluster_centers_\n",
    "\n",
    "    # Convert cluster centers from LAB to RGB\n",
    "    cluster_centers_rgb = color.lab2rgb(cluster_centers_lab.reshape(1, -1, 3))\n",
    "    cluster_centers_rgb = np.squeeze(cluster_centers_rgb)\n",
    "    cluster_centers_rgb_uint8 = np.clip(cluster_centers_rgb * 255, 0, 255).astype(int)\n",
    "\n",
    "    # Step 6: Quantify and visualize cluster sizes\n",
    "    labels = kmeans.labels_\n",
    "    counts = Counter(labels)\n",
    "    total_pixels = sum(counts.values())\n",
    "\n",
    "    # Sort clusters by the number of pixels\n",
    "    sorted_counts = counts.most_common()\n",
    "    sorted_cluster_indices = [item[0] for item in sorted_counts]\n",
    "    sorted_cluster_sizes = [item[1] for item in sorted_counts]\n",
    "    sorted_cluster_percentages = [(count / total_pixels) * 100 for count in sorted_cluster_sizes]\n",
    "    sorted_colors_rgb = np.array([cluster_centers_rgb_uint8[i] for i in sorted_cluster_indices])\n",
    "    sorted_colors_lab = np.array([cluster_centers_lab[i] for i in sorted_cluster_indices])\n",
    "\n",
    "    # *** Compute Additional Image Metrics ***\n",
    "\n",
    "    # Convert LAB to HSV for saturation metrics\n",
    "    image_hsv = color.rgb2hsv(image_normalized)\n",
    "    saturation = image_hsv[:, :, 1]\n",
    "    mean_saturation = np.mean(saturation)\n",
    "    median_saturation = np.median(saturation)\n",
    "    std_saturation = np.std(saturation)\n",
    "\n",
    "    # Luminance Metrics\n",
    "    l_channel = image_lab[:, :, 0]\n",
    "\n",
    "    # *** Outlier Removal based on Pixel Frequency ***\n",
    "    l_flat = l_channel.flatten()\n",
    "    total_pixels = l_flat.size\n",
    "    \n",
    "    # Compute histogram of luminance values\n",
    "    hist, bin_edges = np.histogram(l_flat, bins=256, range=(0, 100))\n",
    "    \n",
    "    # Define a frequency threshold (e.g., pixels that make up less than 0.05% of the image)\n",
    "    frequency_threshold = total_pixels * 0.0005  # Adjust this value as needed\n",
    "    \n",
    "    # Identify bins where the frequency exceeds the threshold\n",
    "    valid_bins = np.where(hist > frequency_threshold)[0]\n",
    "    \n",
    "    if valid_bins.size > 0:\n",
    "        l_min = bin_edges[valid_bins[0]]\n",
    "        l_max = bin_edges[valid_bins[-1] + 1]\n",
    "    else:\n",
    "        l_min = l_flat.min()\n",
    "        l_max = l_flat.max()\n",
    "    \n",
    "    # Filter out the outliers\n",
    "    l_filtered = l_flat[(l_flat >= l_min) & (l_flat <= l_max)]\n",
    "\n",
    "\n",
    "    mean_luminance = np.mean(l_filtered)\n",
    "    median_luminance = np.median(l_filtered)\n",
    "    std_luminance = np.std(l_filtered)\n",
    "    dynamic_range = l_max - l_min\n",
    "\n",
    "    # Contrast Metrics using adjusted min and max\n",
    "    rms_contrast = np.sqrt(np.mean(l_filtered**2))\n",
    "    michelson_contrast = (l_max - l_min) / (l_max + l_min)\n",
    "\n",
    "    # Skewness and Kurtosis of Luminance\n",
    "    lum_skew = skew(l_filtered)\n",
    "    lum_kurt = kurtosis(l_filtered)\n",
    "\n",
    "    # Texture Features using GLCM (use original l_channel)\n",
    "    glcm = feature.graycomatrix(l_channel.astype(np.uint8), distances=[5], angles=[0],\n",
    "                                levels=256, symmetric=True, normed=True)\n",
    "    glcm_contrast = feature.graycoprops(glcm, 'contrast')[0, 0]\n",
    "    glcm_correlation = feature.graycoprops(glcm, 'correlation')[0, 0]\n",
    "\n",
    "    # Sharpness using Variance of Laplacian (use original l_channel)\n",
    "    laplacian_var = cv2.Laplacian(l_channel, cv2.CV_64F).var()\n",
    "\n",
    "    # *** Compile All Metrics ***\n",
    "    all_metrics = {\n",
    "        'Mean Luminance': mean_luminance,\n",
    "        'Median Luminance': median_luminance,\n",
    "        'Std Luminance': std_luminance,\n",
    "        'Dynamic Range': dynamic_range,\n",
    "        'RMS Contrast': rms_contrast,\n",
    "        'Michelson Contrast': michelson_contrast,\n",
    "        'Mean Saturation': mean_saturation,\n",
    "        'Median Saturation': median_saturation,\n",
    "        'Std Saturation': std_saturation,\n",
    "        'GLCM Contrast': glcm_contrast,\n",
    "        'GLCM Correlation': glcm_correlation,\n",
    "        'Laplacian Variance': laplacian_var,\n",
    "        'Luminance Skewness': lum_skew,\n",
    "        'Luminance Kurtosis': lum_kurt,\n",
    "        'Min Luminance': l_min,\n",
    "        'Max Luminance': l_max,\n",
    "        'KMeans Clustering': {\n",
    "            'Number of Clusters': k,\n",
    "            'Cluster Centers (RGB)': sorted_colors_rgb.tolist(),\n",
    "            'Cluster Centers (LAB)': sorted_colors_lab.tolist(),\n",
    "            'Cluster Counts': sorted_cluster_sizes,\n",
    "            'Cluster Percentages': [pct for pct in sorted_cluster_percentages]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # *** Insert Data into SQLite Database ***\n",
    "    insert_luminance(conn, image_id, all_metrics)\n",
    "    insert_saturation(conn, image_id, all_metrics)\n",
    "    insert_glcm(conn, image_id, all_metrics)\n",
    "    insert_laplacian(conn, image_id, all_metrics['Laplacian Variance'])\n",
    "    insert_kmeans_clustering(conn, image_id, all_metrics['KMeans Clustering'])\n",
    "\n",
    "    return True\n",
    "\n",
    "# Main loop over posts\n",
    "for index, post in enumerate(posts, start=1):\n",
    "    # Extract post data\n",
    "    shortcode = post.shortcode\n",
    "    post_date = post.date_utc.strftime('%Y-%m-%d %H:%M:%S')  # Format date as string\n",
    "    caption = post.caption if post.caption else \"\"\n",
    "    post_username = post.owner_username\n",
    "\n",
    "    # Check if the post already exists in the database\n",
    "    cursor.execute('SELECT id FROM Posts WHERE shortcode = ?', (shortcode,))\n",
    "    result = cursor.fetchone()\n",
    "    if result is not None:\n",
    "        # Post already exists in the database\n",
    "        print(f\"Post {shortcode} already exists in database, skipping download and processing.\")\n",
    "        continue  # Skip to the next post\n",
    "    else:\n",
    "        # Insert the new post into the database\n",
    "        cursor.execute('''\n",
    "        INSERT INTO Posts (shortcode, username, caption, post_date)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "        ''', (shortcode, post_username, caption, post_date))\n",
    "        post_id = cursor.lastrowid\n",
    "\n",
    "    # Set the directory for the post\n",
    "    dirname = f\"../gallery/public/img/{username}/{post.date_utc:%Y-%m-%d_%H-%M-%S}_{post.shortcode}\"\n",
    "    L.dirname_pattern = dirname\n",
    "\n",
    "    # Start the timer for this post\n",
    "    post_start_time = time.time()\n",
    "\n",
    "    # Download the post (images only)\n",
    "    L.download_post(post, target='')\n",
    "\n",
    "    # End the timer for this post\n",
    "    post_end_time = time.time()\n",
    "\n",
    "    # Calculate time taken for the current post\n",
    "    time_for_post = post_end_time - post_start_time\n",
    "\n",
    "    # Calculate total elapsed time so far\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Estimate remaining time based on the average time per post\n",
    "    avg_time_per_post = elapsed_time / index\n",
    "    remaining_posts = total_posts - index\n",
    "    estimated_remaining_time = avg_time_per_post * remaining_posts\n",
    "\n",
    "    # List the image files in 'dirname'\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(dirname):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "\n",
    "    # Process each image\n",
    "    for image_file in image_files:\n",
    "        # Absolute file path\n",
    "        absolute_file_path = os.path.abspath(image_file)\n",
    "        # Relative file path (after 'public')\n",
    "        try:\n",
    "            public_index = absolute_file_path.index('public') + len('public')\n",
    "            relative_file_path = absolute_file_path[public_index:].replace('\\\\', '/')\n",
    "        except ValueError:\n",
    "            # 'public' not found in path, handle accordingly\n",
    "            print(f\"'public' not found in the path: {absolute_file_path}\")\n",
    "            relative_file_path = f\"/img/{username}/{post.date_utc:%Y-%m-%d_%H-%M-%S}_{post.shortcode}/{os.path.basename(image_file)}\"\n",
    "        # Prepend '/' to make it an absolute URL path\n",
    "        relative_file_path = f\"/{relative_file_path.lstrip('/')}\"\n",
    "        # Filename\n",
    "        image_filename = os.path.basename(image_file)\n",
    "        # Processed at timestamp\n",
    "        processed_at = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "        # Insert into Images table\n",
    "        cursor.execute('''\n",
    "        INSERT OR IGNORE INTO Images (absolute_file_path, relative_file_path, filename, processed_at, post_id)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "        ''', (absolute_file_path, relative_file_path, image_filename, processed_at, post_id))\n",
    "\n",
    "        # Retrieve the image ID\n",
    "        cursor.execute('SELECT id FROM Images WHERE absolute_file_path = ?', (absolute_file_path,))\n",
    "        image_id = cursor.fetchone()[0]\n",
    "\n",
    "        # Process the image\n",
    "        success = process_image(image_file, image_id, conn)\n",
    "        if success:\n",
    "            print(f\"Processed image {image_filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to process image {image_filename}\")\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Downloaded {index}/{total_posts} posts.\")\n",
    "    print(f\"Time for last post: {time_for_post:.2f} seconds.\")\n",
    "    print(f\"Estimated remaining time: {timedelta(seconds=int(estimated_remaining_time))}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Calculate total time spent after all posts are downloaded\n",
    "total_time_spent = time.time() - start_time\n",
    "print(f\"All {total_posts} posts downloaded and processed.\")\n",
    "print(f\"Total time spent: {timedelta(seconds=int(total_time_spent))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
