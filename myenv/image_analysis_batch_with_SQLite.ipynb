{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database initialized successfully.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 186\u001b[0m\n\u001b[1;32m    183\u001b[0m profile \u001b[38;5;241m=\u001b[39m instaloader\u001b[38;5;241m.\u001b[39mProfile\u001b[38;5;241m.\u001b[39mfrom_username(L\u001b[38;5;241m.\u001b[39mcontext, username)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Fetch all posts from the profile\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m posts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_posts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Convert to list to calculate length\u001b[39;00m\n\u001b[1;32m    188\u001b[0m total_posts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(posts)  \u001b[38;5;66;03m# Get total number of posts\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal posts to download: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_posts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/custom_gallery/myenv/lib/python3.12/site-packages/instaloader/structures.py:1186\u001b[0m, in \u001b[0;36mProfile.get_posts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve all posts from a profile.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \n\u001b[1;32m   1184\u001b[0m \u001b[38;5;124;03m:rtype: NodeIterator[Post]\"\"\"\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obtain_metadata()\n\u001b[0;32m-> 1186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNodeIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxdt_api__v1__feed__user_timeline_graphql_connection\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_wrapper\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iphone_struct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_variables\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minclude_relationship_info\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatest_besties_reel_media\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatest_reel_media\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musername\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musername\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_referer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.instagram.com/\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musername\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_first\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mProfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_is_newest_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m7898261790222653\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_hash\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/custom_gallery/myenv/lib/python3.12/site-packages/instaloader/nodeiterator.py:100\u001b[0m, in \u001b[0;36mNodeIterator.__init__\u001b[0;34m(self, context, query_hash, edge_extractor, node_wrapper, query_variables, query_referer, first_data, is_first, doc_id)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_before \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m+\u001b[39m NodeIterator\u001b[38;5;241m.\u001b[39m_shelf_life\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_node: Optional[Dict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_first \u001b[38;5;241m=\u001b[39m is_first\n",
      "File \u001b[0;32m~/Projects/custom_gallery/myenv/lib/python3.12/site-packages/instaloader/nodeiterator.py:106\u001b[0m, in \u001b[0;36mNodeIterator._query\u001b[0;34m(self, after)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, after: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_doc_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_doc_id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_doc_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/custom_gallery/myenv/lib/python3.12/site-packages/instaloader/nodeiterator.py:119\u001b[0m, in \u001b[0;36mNodeIterator._query_doc_id\u001b[0;34m(self, doc_id, after)\u001b[0m\n\u001b[1;32m    116\u001b[0m     pagination_variables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[1;32m    117\u001b[0m     pagination_variables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    118\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edge_extractor(\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_id_graphql_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpagination_variables\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_referer\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_before \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m+\u001b[39m NodeIterator\u001b[38;5;241m.\u001b[39m_shelf_life\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Projects/custom_gallery/myenv/lib/python3.12/site-packages/instaloader/instaloadercontext.py:543\u001b[0m, in \u001b[0;36mInstaloaderContext.doc_id_graphql_query\u001b[0;34m(self, doc_id, variables, referer)\u001b[0m\n\u001b[1;32m    539\u001b[0m         tmpsession\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreferer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mquote(referer)\n\u001b[1;32m    541\u001b[0m     variables_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(variables, separators\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 543\u001b[0m     resp_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgraphql/query\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvariables\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables_json\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m                                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdoc_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m                                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserver_timestamps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmpsession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m                              \u001b[49m\u001b[43muse_post\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resp_json:\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphQL response did not contain a \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m field.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/custom_gallery/myenv/lib/python3.12/site-packages/instaloader/instaloadercontext.py:411\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[1;32m    409\u001b[0m sess \u001b[38;5;241m=\u001b[39m session \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_sleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_graphql_query:\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_controller\u001b[38;5;241m.\u001b[39mwait_before_query(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_hash\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Projects/custom_gallery/myenv/lib/python3.12/site-packages/instaloader/instaloadercontext.py:367\u001b[0m, in \u001b[0;36mInstaloaderContext.do_sleep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sleep a short time if self.sleep is set. Called before each request to instagram.com.\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msleep:\n\u001b[0;32m--> 367\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpovariate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sqlite3\n",
    "import instaloader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import color, feature\n",
    "from collections import Counter\n",
    "from scipy.stats import skew, kurtosis\n",
    "import cv2\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# Check required libraries\n",
    "def check_libraries():\n",
    "    required_libraries = {\n",
    "        'numpy': 'numpy',\n",
    "        'Pillow': 'PIL',\n",
    "        'scikit-learn': 'sklearn',\n",
    "        'scikit-image': 'skimage',\n",
    "        'opencv-python': 'cv2',\n",
    "        'scipy': 'scipy'\n",
    "    }\n",
    "\n",
    "    missing_libraries = []\n",
    "\n",
    "    for pip_name, import_name in required_libraries.items():\n",
    "        try:\n",
    "            __import__(import_name)\n",
    "        except ImportError:\n",
    "            missing_libraries.append(pip_name)\n",
    "\n",
    "    if missing_libraries:\n",
    "        print(f\"The following libraries are required but not installed: {', '.join(missing_libraries)}\")\n",
    "        print(\"Please install them using pip:\")\n",
    "        print(f\"pip install {' '.join(missing_libraries)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# Perform the library check\n",
    "check_libraries()\n",
    "\n",
    "# Define the database path\n",
    "DATABASE_PATH = os.path.join(\"/Users/greyson/Projects/custom_gallery/gallery/prisma\", 'image_analysis.db')\n",
    "\n",
    "def connect_db():\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    conn.execute('PRAGMA foreign_keys = ON;')  # Enable foreign key support\n",
    "    return conn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_posts = len(posts)  # Get total number of posts\n",
    "print(f\"Total posts to download: {total_posts}\")\n",
    "\n",
    "# Track progress and download time\n",
    "start_time = time.time()  # Track the time when the download starts\n",
    "\n",
    "# Connect to the database\n",
    "conn = connect_db()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def is_similar(row, tolerance=10):\n",
    "    \"\"\"\n",
    "    Check if all pixels in the row are similar within the given tolerance.\n",
    "    \"\"\"\n",
    "    # Compute the difference between max and min for each channel\n",
    "    diff = row.max(axis=0) - row.min(axis=0)\n",
    "    return np.all(diff < tolerance)\n",
    "\n",
    "def find_letterbox_height(image_np, tolerance=10, min_height=10, from_top=True):\n",
    "    \"\"\"\n",
    "    Find the height of the letterbox from the top or bottom.\n",
    "    \"\"\"\n",
    "    height, width, _ = image_np.shape\n",
    "    letterbox_height = 0\n",
    "    range_y = range(height) if from_top else range(height-1, -1, -1)\n",
    "\n",
    "    for y in range_y:\n",
    "        row = image_np[y, :, :]\n",
    "        if is_similar(row, tolerance):\n",
    "            letterbox_height +=1\n",
    "        else:\n",
    "            break\n",
    "    # Ensure the detected letterbox is at least min_height pixels\n",
    "    if letterbox_height >= min_height:\n",
    "        return letterbox_height\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def remove_letterbox(image_np, tolerance=10, min_letterbox_height=10):\n",
    "    \"\"\"\n",
    "    Detect and remove letterboxing from the top and bottom of the image.\n",
    "    Returns the top and bottom letterbox heights, and the cropped image.\n",
    "    \"\"\"\n",
    "    top_height = find_letterbox_height(image_np, tolerance, min_letterbox_height, from_top=True)\n",
    "    bottom_height = find_letterbox_height(image_np, tolerance, min_letterbox_height, from_top=False)\n",
    "\n",
    "    # and if the absolute value of the difference between the top and bottom is less than min_height\n",
    "    if (top_height > 0 or bottom_height > 0) and abs(top_height - bottom_height) < min_letterbox_height:\n",
    "        cropped_image = image_np[top_height: image_np.shape[0] - bottom_height, :, :]\n",
    "        print(f\"Removed letterbox: Top={top_height}px, Bottom={bottom_height}px\")\n",
    "        return top_height, bottom_height, cropped_image\n",
    "    else:\n",
    "        print(\"No letterbox detected.\")\n",
    "        return 0, 0, image_np\n",
    "\n",
    "def insert_luminance(conn, image_id, luminance_metrics):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Luminance (\n",
    "        image_id, mean_luminance, median_luminance, std_luminance,\n",
    "        dynamic_range, rms_contrast, michelson_contrast,\n",
    "        luminance_skewness, luminance_kurtosis,\n",
    "        min_luminance, max_luminance\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        luminance_metrics[\"Mean Luminance\"],\n",
    "        luminance_metrics[\"Median Luminance\"],\n",
    "        luminance_metrics[\"Std Luminance\"],\n",
    "        luminance_metrics[\"Dynamic Range\"],\n",
    "        luminance_metrics[\"RMS Contrast\"],\n",
    "        luminance_metrics[\"Michelson Contrast\"],\n",
    "        luminance_metrics[\"Luminance Skewness\"],\n",
    "        luminance_metrics[\"Luminance Kurtosis\"],\n",
    "        luminance_metrics[\"Min Luminance\"],\n",
    "        luminance_metrics[\"Max Luminance\"]\n",
    "    ))\n",
    "    conn.commit()\n",
    "\n",
    "def insert_saturation(conn, image_id, saturation_metrics):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Saturation (\n",
    "        image_id, mean_saturation, median_saturation, std_saturation\n",
    "    ) VALUES (?, ?, ?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        saturation_metrics[\"Mean Saturation\"],\n",
    "        saturation_metrics[\"Median Saturation\"],\n",
    "        saturation_metrics[\"Std Saturation\"]\n",
    "    ))\n",
    "    conn.commit()\n",
    "\n",
    "def insert_glcm(conn, image_id, glcm_metrics):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    INSERT INTO GLCM (\n",
    "        image_id, contrast, correlation\n",
    "    ) VALUES (?, ?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        glcm_metrics[\"GLCM Contrast\"],\n",
    "        glcm_metrics[\"GLCM Correlation\"]\n",
    "    ))\n",
    "    conn.commit()\n",
    "\n",
    "def insert_laplacian(conn, image_id, laplacian_var):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Laplacian (\n",
    "        image_id, variance\n",
    "    ) VALUES (?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        laplacian_var\n",
    "    ))\n",
    "    conn.commit()\n",
    "\n",
    "def insert_kmeans_clustering(conn, image_id, clustering_data):\n",
    "    cursor = conn.cursor()\n",
    "    num_clusters = clustering_data[\"Number of Clusters\"]\n",
    "    cursor.execute('''\n",
    "    INSERT INTO KMeansClustering (\n",
    "        image_id, num_clusters\n",
    "    ) VALUES (?, ?)\n",
    "    ''', (\n",
    "        image_id,\n",
    "        num_clusters\n",
    "    ))\n",
    "    conn.commit()\n",
    "    # Retrieve the last inserted row id for KMeansClustering\n",
    "    clustering_id = cursor.lastrowid\n",
    "\n",
    "    clusters_rgb = clustering_data[\"Cluster Centers (RGB)\"]\n",
    "    clusters_lab = clustering_data[\"Cluster Centers (LAB)\"]\n",
    "    counts = clustering_data[\"Cluster Counts\"]\n",
    "    percentages = clustering_data[\"Cluster Percentages\"]\n",
    "\n",
    "    for idx, (color_rgb, color_lab, count, pct) in enumerate(zip(clusters_rgb, clusters_lab, counts, percentages)):\n",
    "        r, g, b = color_rgb\n",
    "        l_val, a_val, b_val = color_lab\n",
    "        cursor.execute('''\n",
    "        INSERT INTO Clusters (\n",
    "            clustering_id, cluster_index, r, g, b, l, a, b_channel, count, percentage\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            clustering_id,\n",
    "            idx + 1,  # cluster_index starting from 1\n",
    "            r,\n",
    "            g,\n",
    "            b,\n",
    "            l_val,\n",
    "            a_val,\n",
    "            b_val,\n",
    "            count,\n",
    "            float(pct)  # Directly use pct as it's already a float\n",
    "        ))\n",
    "    conn.commit()\n",
    "\n",
    "def process_image(image_path, image_id, conn):\n",
    "    \"\"\"\n",
    "    Process a single image: remove letterbox, perform k-means clustering,\n",
    "    compute metrics, and save them to the SQLite database.\n",
    "    Returns True if processed successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found at path: {image_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {image_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    # Ensure the image is in RGB format\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "\n",
    "    # Remove alpha channel if present\n",
    "    if image_np.shape[2] == 4:\n",
    "        image_np = image_np[:, :, :3]\n",
    "\n",
    "    # *** Detect and Remove Letterbox ***\n",
    "    # Parameters can be adjusted based on the expected letterbox characteristics\n",
    "    tolerance = 2              # Tolerance for color similarity (0-255)\n",
    "    min_letterbox_height = 10  # Minimum height in pixels to consider as letterbox\n",
    "\n",
    "    top_height, bottom_height, image_np = remove_letterbox(image_np, tolerance, min_letterbox_height)\n",
    "\n",
    "    # Update the Images table with letterbox heights\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    UPDATE Images\n",
    "    SET letterbox_top = ?, letterbox_bottom = ?\n",
    "    WHERE id = ?\n",
    "    ''', (top_height, bottom_height, image_id))\n",
    "    conn.commit()\n",
    "\n",
    "    # Proceed with image processing\n",
    "    # Step 2: Normalize and convert to LAB color space\n",
    "    image_normalized = image_np / 255.0\n",
    "    image_lab = color.rgb2lab(image_normalized)\n",
    "\n",
    "    # Step 3: Reshape image data for clustering\n",
    "    pixels_lab = image_lab.reshape(-1, 3)\n",
    "\n",
    "    # Step 4: Perform k-means clustering with k=8\n",
    "    k = 8  # Set the number of clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(pixels_lab)\n",
    "\n",
    "    # Step 5: Process cluster centers\n",
    "    cluster_centers_lab = kmeans.cluster_centers_\n",
    "\n",
    "    # Convert cluster centers from LAB to RGB\n",
    "    cluster_centers_rgb = color.lab2rgb(cluster_centers_lab.reshape(1, -1, 3))\n",
    "    cluster_centers_rgb = np.squeeze(cluster_centers_rgb)\n",
    "    cluster_centers_rgb_uint8 = np.clip(cluster_centers_rgb * 255, 0, 255).astype(int)\n",
    "\n",
    "    # Step 6: Quantify and visualize cluster sizes\n",
    "    labels = kmeans.labels_\n",
    "    counts = Counter(labels)\n",
    "    total_pixels = sum(counts.values())\n",
    "\n",
    "    # Sort clusters by the number of pixels\n",
    "    sorted_counts = counts.most_common()\n",
    "    sorted_cluster_indices = [item[0] for item in sorted_counts]\n",
    "    sorted_cluster_sizes = [item[1] for item in sorted_counts]\n",
    "    sorted_cluster_percentages = [(count / total_pixels) * 100 for count in sorted_cluster_sizes]\n",
    "    sorted_colors_rgb = np.array([cluster_centers_rgb_uint8[i] for i in sorted_cluster_indices])\n",
    "    sorted_colors_lab = np.array([cluster_centers_lab[i] for i in sorted_cluster_indices])\n",
    "\n",
    "    # *** Compute Additional Image Metrics ***\n",
    "\n",
    "    # Convert LAB to HSV for saturation metrics\n",
    "    image_hsv = color.rgb2hsv(image_normalized)\n",
    "    saturation = image_hsv[:, :, 1]\n",
    "    mean_saturation = np.mean(saturation)\n",
    "    median_saturation = np.median(saturation)\n",
    "    std_saturation = np.std(saturation)\n",
    "\n",
    "    # Luminance Metrics\n",
    "    l_channel = image_lab[:, :, 0]\n",
    "\n",
    "    # *** Outlier Removal based on Pixel Frequency ***\n",
    "    l_flat = l_channel.flatten()\n",
    "    total_pixels = l_flat.size\n",
    "    \n",
    "    # Compute histogram of luminance values\n",
    "    hist, bin_edges = np.histogram(l_flat, bins=256, range=(0, 100))\n",
    "    \n",
    "    # Define a frequency threshold (e.g., pixels that make up less than 0.05% of the image)\n",
    "    frequency_threshold = total_pixels * 0.0005  # Adjust this value as needed\n",
    "    \n",
    "    # Identify bins where the frequency exceeds the threshold\n",
    "    valid_bins = np.where(hist > frequency_threshold)[0]\n",
    "    \n",
    "    if valid_bins.size > 0:\n",
    "        l_min = bin_edges[valid_bins[0]]\n",
    "        l_max = bin_edges[valid_bins[-1] + 1]\n",
    "    else:\n",
    "        l_min = l_flat.min()\n",
    "        l_max = l_flat.max()\n",
    "    \n",
    "    # Filter out the outliers\n",
    "    l_filtered = l_flat[(l_flat >= l_min) & (l_flat <= l_max)]\n",
    "\n",
    "\n",
    "    mean_luminance = np.mean(l_filtered)\n",
    "    median_luminance = np.median(l_filtered)\n",
    "    std_luminance = np.std(l_filtered)\n",
    "    dynamic_range = l_max - l_min\n",
    "\n",
    "    # Contrast Metrics using adjusted min and max\n",
    "    rms_contrast = np.sqrt(np.mean(l_filtered**2))\n",
    "    michelson_contrast = (l_max - l_min) / (l_max + l_min)\n",
    "\n",
    "    # Skewness and Kurtosis of Luminance\n",
    "    lum_skew = skew(l_filtered)\n",
    "    lum_kurt = kurtosis(l_filtered)\n",
    "\n",
    "    # Texture Features using GLCM (use original l_channel)\n",
    "    glcm = feature.graycomatrix(l_channel.astype(np.uint8), distances=[5], angles=[0],\n",
    "                                levels=256, symmetric=True, normed=True)\n",
    "    glcm_contrast = feature.graycoprops(glcm, 'contrast')[0, 0]\n",
    "    glcm_correlation = feature.graycoprops(glcm, 'correlation')[0, 0]\n",
    "\n",
    "    # Sharpness using Variance of Laplacian (use original l_channel)\n",
    "    laplacian_var = cv2.Laplacian(l_channel, cv2.CV_64F).var()\n",
    "\n",
    "    # *** Compile All Metrics ***\n",
    "    all_metrics = {\n",
    "        'Mean Luminance': mean_luminance,\n",
    "        'Median Luminance': median_luminance,\n",
    "        'Std Luminance': std_luminance,\n",
    "        'Dynamic Range': dynamic_range,\n",
    "        'RMS Contrast': rms_contrast,\n",
    "        'Michelson Contrast': michelson_contrast,\n",
    "        'Mean Saturation': mean_saturation,\n",
    "        'Median Saturation': median_saturation,\n",
    "        'Std Saturation': std_saturation,\n",
    "        'GLCM Contrast': glcm_contrast,\n",
    "        'GLCM Correlation': glcm_correlation,\n",
    "        'Laplacian Variance': laplacian_var,\n",
    "        'Luminance Skewness': lum_skew,\n",
    "        'Luminance Kurtosis': lum_kurt,\n",
    "        'Min Luminance': l_min,\n",
    "        'Max Luminance': l_max,\n",
    "        'KMeans Clustering': {\n",
    "            'Number of Clusters': k,\n",
    "            'Cluster Centers (RGB)': sorted_colors_rgb.tolist(),\n",
    "            'Cluster Centers (LAB)': sorted_colors_lab.tolist(),\n",
    "            'Cluster Counts': sorted_cluster_sizes,\n",
    "            'Cluster Percentages': [pct for pct in sorted_cluster_percentages]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # *** Insert Data into SQLite Database ***\n",
    "    insert_luminance(conn, image_id, all_metrics)\n",
    "    insert_saturation(conn, image_id, all_metrics)\n",
    "    insert_glcm(conn, image_id, all_metrics)\n",
    "    insert_laplacian(conn, image_id, all_metrics['Laplacian Variance'])\n",
    "    insert_kmeans_clustering(conn, image_id, all_metrics['KMeans Clustering'])\n",
    "\n",
    "    return True\n",
    "\n",
    "# Main loop over posts\n",
    "for index, post in enumerate(posts, start=1):\n",
    "    # Extract post data\n",
    "    shortcode = post.shortcode\n",
    "    post_date = post.date_utc.strftime('%Y-%m-%d %H:%M:%S')  # Format date as string\n",
    "    caption = post.caption if post.caption else \"\"\n",
    "    post_username = post.owner_username\n",
    "\n",
    "    # Insert or ignore the post into Posts table\n",
    "    cursor.execute('''\n",
    "    INSERT OR IGNORE INTO Posts (shortcode, username, caption, post_date)\n",
    "    VALUES (?, ?, ?, ?)\n",
    "    ''', (shortcode, post_username, caption, post_date))\n",
    "\n",
    "    # Retrieve the post ID\n",
    "    cursor.execute('SELECT id FROM Posts WHERE shortcode = ?', (shortcode,))\n",
    "    post_id = cursor.fetchone()[0]\n",
    "\n",
    "    # Set the directory for the post\n",
    "    dirname = f\"../gallery/public/img/{username}/{post.date_utc:%Y-%m-%d_%H-%M-%S}_{post.shortcode}\"\n",
    "    L.dirname_pattern = dirname\n",
    "\n",
    "    # Start the timer for this post\n",
    "    post_start_time = time.time()\n",
    "\n",
    "    # Download the post (images only)\n",
    "    L.download_post(post, target='')\n",
    "\n",
    "    # End the timer for this post\n",
    "    post_end_time = time.time()\n",
    "\n",
    "    # Calculate time taken for the current post\n",
    "    time_for_post = post_end_time - post_start_time\n",
    "\n",
    "    # Calculate total elapsed time so far\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Estimate remaining time based on the average time per post\n",
    "    avg_time_per_post = elapsed_time / index\n",
    "    remaining_posts = total_posts - index\n",
    "    estimated_remaining_time = avg_time_per_post * remaining_posts\n",
    "\n",
    "    # List the image files in 'dirname'\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(dirname):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "\n",
    "    # Process each image\n",
    "    for image_file in image_files:\n",
    "        # Absolute file path\n",
    "        absolute_file_path = os.path.abspath(image_file)\n",
    "        # Relative file path (after 'public')\n",
    "        try:\n",
    "            public_index = absolute_file_path.index('public') + len('public')\n",
    "            relative_file_path = absolute_file_path[public_index:].replace('\\\\', '/')\n",
    "        except ValueError:\n",
    "            # 'public' not in path, handle accordingly\n",
    "            print(f\"'public' not found in the path: {absolute_file_path}\")\n",
    "            relative_file_path = f\"/img/{username}/{post.date_utc:%Y-%m-%d_%H-%M-%S}_{post.shortcode}/{os.path.basename(image_file)}\"\n",
    "        # Prepend '/' to make it an absolute URL path\n",
    "        relative_file_path = f\"/{relative_file_path.lstrip('/')}\"\n",
    "        # Filename\n",
    "        image_filename = os.path.basename(image_file)\n",
    "        # Processed at timestamp\n",
    "        processed_at = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Insert into Images table\n",
    "        cursor.execute('''\n",
    "        INSERT OR IGNORE INTO Images (absolute_file_path, relative_file_path, filename, processed_at, post_id)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "        ''', (absolute_file_path, relative_file_path, image_filename, processed_at, post_id))\n",
    "\n",
    "        # Retrieve the image ID\n",
    "        cursor.execute('SELECT id FROM Images WHERE absolute_file_path = ?', (absolute_file_path,))\n",
    "        image_id = cursor.fetchone()[0]\n",
    "\n",
    "        # Process the image\n",
    "        success = process_image(image_file, image_id, conn)\n",
    "        if success:\n",
    "            print(f\"Processed image {image_filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to process image {image_filename}\")\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Downloaded {index}/{total_posts} posts.\")\n",
    "    print(f\"Time for last post: {time_for_post:.2f} seconds.\")\n",
    "    print(f\"Estimated remaining time: {timedelta(seconds=int(estimated_remaining_time))}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Calculate total time spent after all posts are downloaded\n",
    "total_time_spent = time.time() - start_time\n",
    "print(f\"All {total_posts} posts downloaded and processed.\")\n",
    "print(f\"Total time spent: {timedelta(seconds=int(total_time_spent))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
